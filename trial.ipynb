{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "## SPLITTING DATA INTO TRAINING DATA, VALIDATION DATA & PREDICTION DATA ##\n",
    "##########################################################################\n",
    "# Making the fractions that are used to split the data into training, testing and validation data.\n",
    "trainingData = 2/3\n",
    "validationData = 1/6\n",
    "predictionData = 1/6\n",
    "# Getting the dimensions of the redWineData and the whiteWineData.\n",
    "redDimension = redWineData.shape\n",
    "whiteDimension = whiteWineData.shape\n",
    "# Getting the number of row that would be the cutoff for red and white wine trianing and validation data. \n",
    "redTrainingRows = redDimension[0] * trainingData\n",
    "redValidationRows = redTrainingRows + (redDimension[0] * validationData)\n",
    "whiteTrainingRows = whiteDimension[0] * trainingData\n",
    "whiteValidationRows = whiteTrainingRows + (whiteDimension[0] * validationData)\n",
    "# Getting the training and y data for the red wine. \n",
    "redTrainingData = redWineData.loc[0:redTrainingRows]\n",
    "redQualityTrainingData = redTrainingData['quality']\n",
    "redTrainingData = redTrainingData.drop('quality', axis=1)\n",
    "# Getting the validation and y data for red wine.\n",
    "redValidationData = redWineData.loc[redTrainingRows+1:redValidationRows]\n",
    "redQualityValidationData = redValidationData['quality']\n",
    "redValidationData = redValidationData.drop('quality', axis=1)\n",
    "# Getting the test and y data for red wine. \n",
    "redTestData = redWineData.loc[redValidationRows+1:]\n",
    "redQualityTestData = redTestData['quality']\n",
    "redTestData = redTestData.drop('quality', axis=1)\n",
    "# Getting the training and y data for the white wine. \n",
    "whiteTrainingData = whiteWineData.loc[0:whiteTrainingRows]\n",
    "whiteQualityTrainingData = whiteTrainingData['quality']\n",
    "whiteTrainingData = whiteTrainingData.drop('quality', axis=1)\n",
    "# Getting the validation and y data for red wine.\n",
    "whiteValidationData = whiteWineData.loc[whiteTrainingRows+1:whiteValidationRows]\n",
    "whiteQualityValidationData = whiteValidationData['quality']\n",
    "whiteValidationData = whiteValidationData.drop('quality', axis=1)\n",
    "# Getting the test and y data for red wine. \n",
    "whiteTestData = whiteWineData.loc[whiteValidationRows+1:]\n",
    "whiteQualityTestData = whiteTestData['quality']\n",
    "whiteTestData = whiteTestData.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Does it make sense to scale the whole dataaset, or does it make sense to scale each individual feature one at a time?\n",
    "# I don't see the use to scale the entire dataset around one common mean, rather than scaling to the mean of each individual feature. \n",
    "# The only was you would scale the entire dataset if you had very similar features, otherwise I think it makes more sense to scale and fit each feature individually. \n",
    "# NO NEED TO SCALE DATA. THIS WAS DONE AS AN ATTEMPT TO TRY GET MORE ACCURATE RESULTS.\n",
    "\n",
    "# Creating a standard scalar object. \n",
    "sc = StandardScaler()\n",
    "# Scaling all the training, test and validation data.\n",
    "trial = sc.fit_transform(np.array(redTrainingData['density']).reshape(-1,1))\n",
    "redTrainingDataScaled = sc.fit_transform(redTrainingData)\n",
    "redValidationDataScaled = sc.fit_transform(redValidationData)\n",
    "redTestDataScaled = sc.fit_transform(redTestData)\n",
    "whiteTrainingDataScaled = sc.fit_transform(whiteTrainingData)\n",
    "whiteValidationDataScaled = sc.fit_transform(whiteValidationData)\n",
    "whiteTestDataScaled = sc.fit_transform(whiteTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# i don't see the use of the scaling and normalize. Should do one or the either, not both. \n",
    "# Normalize is better as you can scale each feature independently.\n",
    "# I think this is better than scaling the data. \n",
    "# USED THIS AS THE SCALING METHOD\n",
    "a = preprocessing.normalize(redTrainingData, axis=0)\n",
    "b = preprocessing.normalize(redValidationData, axis=0)\n",
    "c = preprocessing.normalize(redTestData, axis=0)\n",
    "d = preprocessing.normalize(whiteTrainingData, axis=0)\n",
    "e = preprocessing.normalize(whiteValidationData, axis=0)\n",
    "f = preprocessing.normalize(whiteTestData, axis=0)\n",
    "redTrainingDataNormalized = pd.DataFrame(a, columns = redTrainingData.columns)\n",
    "redValidationDataNormalized = pd.DataFrame(b, columns = redValidationData.columns)\n",
    "redTestDataNormalized = pd.DataFrame(c, columns = redTestData.columns)\n",
    "whiteTrainingDataNormalized = pd.DataFrame(d, columns = whiteTrainingData.columns)\n",
    "whiteValidationDataNormalized = pd.DataFrame(e, columns = whiteValidationData.columns)\n",
    "whiteTestDataNormalized = pd.DataFrame(f, columns = whiteTestData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "## PRINCIPAL COMPONENT ANALYSIS FOR RED AND WHITE WINE ##\n",
    "#########################################################\n",
    "# GETTING THE MOST SIGNIFICANT FEATURES USING PCA.\n",
    "# Making the PCA object, and applying the first 2 components of it.\n",
    "pca = PCA(0.95)\n",
    "# Applying the PCA to the normalized red and white wine data.\n",
    "redTrainingDataPCA = pca.fit_transform(redTrainingDataNormalized)\n",
    "redValidationDataPCA = pca.fit_transform(redValidationDataNormalized)\n",
    "redTestDataPCA = pca.fit_transform(redTestDataNormalized)\n",
    "whiteTrainingDataPCA = pca.fit_transform(whiteTrainingDataNormalized)\n",
    "whiteValidationDataPCA = pca.fit_transform(whiteValidationDataNormalized)\n",
    "whiteTestDataPCA = pca.fit_transform(whiteTestDataNormalized)\n",
    "# Getting the explained variance ratio the trianing data.\n",
    "explainedVariance = pca.explained_variance_ratio_\n",
    "# Getting the cumilative explained variance ratio.\n",
    "cumSumExplainedVariance = np.cumsum(explainedVariance)\n",
    "# Making the plot to compare the explained variance and the cumilative explained variance.\n",
    "plt.bar(range(0,len(explainedVariance)), explainedVariance, alpha=0.5, align='center', label='Individual Explained Variance')\n",
    "plt.step(range(0,len(cumSumExplainedVariance)), cumSumExplainedVariance, where='mid',label='Cumulative Explained Variance')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Component Index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "# Making a logistic regression object.\n",
    "redWineLR = LogisticRegression()\n",
    "redWineLR1 = LogisticRegression()\n",
    "# Fitting the model with a normalized x training and y training data.\n",
    "redWineLR.fit(redTrainingDataPCA, np.ravel(redQualityTrainingData))\n",
    "redWineLR1.fit(redTrainingDataNormalized, np.ravel(redQualityTrainingData))\n",
    "# Getting the score for the normalized x training and y training data. \n",
    "redWineTrainingScorePCA = redWineLR.score(redTrainingDataPCA, redQualityTrainingData)\n",
    "redWineTrainingScore = redWineLR1.score(redTrainingDataNormalized, redQualityTrainingData)\n",
    "# Printing the score for the training data.\n",
    "print(\"Fit score for the training data with PCA of the Red Wine Logistic Regression Model: \" + str(redWineTrainingScorePCA))\n",
    "print(\"Fit score for the training data of the Red Wine Logistic Regression Model: \" + str(redWineTrainingScore))\n",
    "# Getting the score for the normalized x validation and y validation data.\n",
    "redWineValidationScorePCA = redWineLR.score(redValidationDataPCA, redQualityValidationData)\n",
    "redWineValidationScore = redWineLR1.score(redValidationDataNormalized, redQualityValidationData)\n",
    "# Printing the score for the validation data.\n",
    "print(\"Fit score for the vaildation data with PCA of the Red Wine Logistic Regression Model: \" + str(redWineValidationScorePCA))\n",
    "print(\"Fit score for the validation data of the Red Wine Logistic Regression Model: \" + str(redWineValidationScore))\n",
    "# Getting the score for the normalized x test and y test data.\n",
    "redWineTestScorePCA = redWineLR.score(redTestDataPCA, redQualityTestData)\n",
    "redWineTestScore = redWineLR1.score(redTestDataNormalized, redQualityTestData)\n",
    "# Printing the score for the test data.\n",
    "print(\"Fit score for the test data with PCA of the Red Wine Logistic Regression Model: \" + str(redWineTestScorePCA))\n",
    "print(\"Fit score for the test data of the Red Wine Logistic Regression Model: \" + str(redWineTestScore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
