{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## IMPORTS ##\n",
    "#############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "## READING RED AND WHITE WINE DATA ##\n",
    "#####################################\n",
    "redWineData = pd.read_csv(\"./data/winequality-red.csv\")\n",
    "whiteWineData = pd.read_csv(\"./data/winequality-white.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The red wine training data has 1067 rows.\n",
      "The red wine test data has 532 rows.\n",
      "The white wine training data has 3266 rows.\n",
      "The white wine test data has 1631 rows.\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "## SPLITTING DATA INTO TRAINING DATA & TEST DATA ##\n",
    "###################################################\n",
    "# Making the fractions that are used to split the data into training, testing and validation data.\n",
    "trainingData = 2/3\n",
    "testData = 1/3\n",
    "# Getting the dimensions of the redWineData and the whiteWineData.\n",
    "redDimension = redWineData.shape\n",
    "whiteDimension = whiteWineData.shape\n",
    "# Getting the number of row that would be the cutoff for red and white wine trianing data. \n",
    "redTrainingRows = redDimension[0] * trainingData\n",
    "whiteTrainingRows = whiteDimension[0] * trainingData\n",
    "# Getting the training and y data for the red wine. \n",
    "redTrainingData = redWineData.loc[0:redTrainingRows]\n",
    "redQualityTrainingData = redTrainingData['quality'].reset_index(drop=True)\n",
    "redTrainingData = redTrainingData.drop('quality', axis=1).reset_index(drop=True)\n",
    "# Getting the test and y data for red wine. \n",
    "redTestData = redWineData.loc[redTrainingRows+1:]\n",
    "redQualityTestData = redTestData['quality'].reset_index(drop=True)\n",
    "redTestData = redTestData.drop('quality', axis=1).reset_index(drop=True)\n",
    "# Getting the training and y data for the white wine. \n",
    "whiteTrainingData = whiteWineData.loc[0:whiteTrainingRows]\n",
    "whiteQualityTrainingData = whiteTrainingData['quality']\n",
    "whiteTrainingData = whiteTrainingData.drop('quality', axis=1).reset_index(drop=True)\n",
    "# Getting the test and y data for red wine. \n",
    "whiteTestData = whiteWineData.loc[whiteTrainingRows+1:]\n",
    "whiteQualityTestData = whiteTestData['quality']\n",
    "whiteTestData = whiteTestData.drop('quality', axis=1).reset_index(drop=True)\n",
    "\n",
    "print(\"The red wine training data has \" + str(len(redTrainingData)) + \" rows.\")\n",
    "print(\"The red wine test data has \" + str(len(redTestData)) + \" rows.\")\n",
    "print(\"The white wine training data has \" + str(len(whiteTrainingData)) + \" rows.\")\n",
    "print(\"The white wine test data has \" + str(len(whiteTestData)) + \" rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Does it make sense to scale the whole dataaset, or does it make sense to scale each individual feature one at a time?\n",
    "# I don't see the use to scale the entire dataset around one common mean, rather than scaling to the mean of each individual feature. \n",
    "# The only was you would scale the entire dataset if you had very similar features, otherwise I think it makes more sense to scale and fit each feature individually. \n",
    "# NO NEED TO SCALE DATA. THIS WAS DONE AS AN ATTEMPT TO TRY GET MORE ACCURATE RESULTS.\n",
    "\n",
    "# Creating a standard scalar object. \n",
    "sc = StandardScaler()\n",
    "# Scaling all the training, test and validation data.\n",
    "redTrainingDataScaled = sc.fit_transform(redTrainingData)\n",
    "redTestDataScaled = sc.fit_transform(redTestData)\n",
    "whiteTrainingDataScaled = sc.fit_transform(whiteTrainingData)\n",
    "whiteTestDataScaled = sc.fit_transform(whiteTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most importance features in the Logistic Regressoin Model made to predict the quality of Red Wine are: \n",
      "('volatile acidity', 3.1970032774585913)\n",
      "('pH', 2.0139131108433563)\n",
      "('fixed acidity', 1.270604443687973)\n",
      "('chlorides', 1.174998107796296)\n",
      "('residual sugar', 1.1293050310318276)\n",
      "The Logistic Regression model made to predict the Red Wine Quality has an accuracy of 0.6109022556390977\n",
      "The 5 most importance features in the Logistic Regressoin Model made to predict the quality of White Wine are: \n",
      "('volatile acidity', 2.377301200392446)\n",
      "('fixed acidity', 1.548316218774758)\n",
      "('chlorides', 1.079301635380718)\n",
      "('total sulfur dioxide', 1.0034373387749984)\n",
      "('free sulfur dioxide', 1.0007232859558965)\n",
      "The Logistic Regression model made to predict the Red Wine Quality has an accuracy of 0.5236051502145923\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "# Making a logistic regression object for the Red Wine Data. \n",
    "redLR = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "# Fitting the model using the training data, with the predictors in the redTrainingData variable, and the redQualityTrainingData is the target variable.\n",
    "redLR.fit(redTrainingData, redQualityTrainingData)\n",
    "# Getting the prediction for the test data.\n",
    "redPredictionsArray = redLR.predict(redTestData)\n",
    "# Making the true data to compare against into a numpy array.\n",
    "redTrueDataArray = np.array(redQualityTestData.values)\n",
    "# Calculating the accuracy of the model constructed. \n",
    "redAccuracyLR = accuracy_score(redPredictionsArray, redTrueDataArray)\n",
    "# Calculating the importance of each feature in the model. We need to take the expoenents as the coef attribute calculates the log of the coefficients.\n",
    "redFeatureImportance = np.exp(redLR.coef_[0])\n",
    "# Making a list of the importance and the column names\n",
    "redFeatureImportanceList = list(zip(redTrainingData.columns, redFeatureImportance))\n",
    "# Sorting this list out in ascending order.\n",
    "redFeatureImportanceList.sort(key=lambda x:x[1], reverse=True)\n",
    "print(\"The 5 most importance features in the Logistic Regressoin Model made to predict the quality of Red Wine are: \")\n",
    "# Getting the 5 most importance features\n",
    "for i in range(5):\n",
    "    print(redFeatureImportanceList[i])\n",
    "# Printing out the accuracy.\n",
    "print(\"The Logistic Regression model made to predict the Red Wine Quality has an accuracy of \" + str(redAccuracyLR))\n",
    "\n",
    "# Making a logistic regression object for the White Wine Data. \n",
    "whiteLR = LogisticRegression(solver='liblinear', max_iter=10000)\n",
    "# Fitting the model using the scaled training data, with the predictors in the redTrainingDataScaled variable, and the redQualityTrainingData is the target variable.\n",
    "whiteLR.fit(whiteTrainingData, whiteQualityTrainingData)\n",
    "# Getting the prediction for the test data.\n",
    "whitePredictionsArray = whiteLR.predict(whiteTestData)\n",
    "# Making the true data to compare against into a numpy array.\n",
    "whiteTrueDataArray = np.array(whiteQualityTestData.values)\n",
    "# Calculating the accuracy of the model constructed. \n",
    "whiteAccuracyLR = accuracy_score(whitePredictionsArray, whiteTrueDataArray)\n",
    "# Calculating the importance of each feature in the model. We need to take the expoenents as the coef attribute calculates the log of the coefficients.\n",
    "whiteFeatureImportance = np.exp(whiteLR.coef_[0])\n",
    "# Making a list of the importance and the column names\n",
    "whiteFeatureImportanceList = list(zip(whiteTrainingData.columns, whiteFeatureImportance))\n",
    "# Sorting this list out in ascending order.\n",
    "whiteFeatureImportanceList.sort(key=lambda x:x[1], reverse=True)\n",
    "print(\"The 5 most importance features in the Logistic Regressoin Model made to predict the quality of White Wine are: \")\n",
    "# Getting the 5 most importance features\n",
    "for i in range(5):\n",
    "    print(whiteFeatureImportanceList[i])\n",
    "# Printing out the accuracy.\n",
    "print(\"The Logistic Regression model made to predict the Red Wine Quality has an accuracy of \" + str(whiteAccuracyLR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most importance features in the Random Forest Classifier Model made to predict the quality of Red Wine are: \n",
      "('alcohol', 0.2846502156130831)\n",
      "('total sulfur dioxide', 0.16854049490383124)\n",
      "('sulphates', 0.13834113520264815)\n",
      "('volatile acidity', 0.11520021137546858)\n",
      "('density', 0.08125250847419094)\n",
      "The Random Forest Classifier model made to predict the Red Wine Quality has an precision of 0.6725133472122985\n",
      "The 5 most importance features in the Random Forest Classifier Model made to predict the quality of Red Wine are: \n",
      "('alcohol', 0.20829446801493368)\n",
      "('density', 0.13687580445075784)\n",
      "('volatile acidity', 0.1362369597623192)\n",
      "('chlorides', 0.08316279742708009)\n",
      "('free sulfur dioxide', 0.07484491798634728)\n",
      "The Random Forest Classifier model made to predict the White Wine Quality has an precision of 0.667593081516935\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## RANDOM FOREST CLASSIFIER MODEL ##\n",
    "####################################\n",
    "# Creating the random forest classifier object.\n",
    "redRF = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)\n",
    "# Fitting the model using the redTrainingDataScaled data, and the redQualityTrainingDataScaled as the target variable.\n",
    "redRF.fit(redTrainingDataScaled, redQualityTrainingData)\n",
    "# Generating the prediction values for the test data. \n",
    "redRFPredictions = redRF.predict(redTestDataScaled)\n",
    "# Turning the predictions numpy array into a Pandas series. \n",
    "redRFPredictions = pd.Series(redRFPredictions, index = redTestData.index)\n",
    "# Calculating the precision of the model. \n",
    "redScoreRF = precision_score(redRFPredictions, redQualityTestData, average=\"weighted\")\n",
    "# Getting the importance of each feature. \n",
    "redFeatureImportance = redRF.feature_importances_\n",
    "# Making a list of the importances and the feature names. \n",
    "redFeatureImportanceList = sorted(list(zip(redTrainingData.columns, redFeatureImportance)), key=lambda x:x[1], reverse=True)\n",
    "print(\"The 5 most importance features in the Random Forest Classifier Model made to predict the quality of Red Wine are: \")\n",
    "# Getting the 5 most importance features\n",
    "for i in range(5):\n",
    "    print(redFeatureImportanceList[i])\n",
    "# Printing out the precision score.\n",
    "print(\"The Random Forest Classifier model made to predict the Red Wine Quality has an precision of \" + str(redScoreRF))\n",
    "\n",
    "# Creating the random forest classifier object.\n",
    "whiteRF = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)\n",
    "# Fitting the model using the redTrainingDataScaled data, and the redQualityTrainingDataScaled as the target variable.\n",
    "whiteRF.fit(whiteTrainingDataScaled, whiteQualityTrainingData)\n",
    "# Generating the prediction values for the test data. \n",
    "whiteRFPredictions = whiteRF.predict(whiteTestDataScaled)\n",
    "# Turning the predictions numpy array into a Pandas series. \n",
    "whiteRFPredictions = pd.Series(whiteRFPredictions, index = whiteTestData.index)\n",
    "# Calculating the precision of the model. \n",
    "whiteScoreRF = precision_score(whiteRFPredictions, whiteQualityTestData, average=\"weighted\")\n",
    "# Getting the importance of each feature. \n",
    "whiteFeatureImportance = whiteRF.feature_importances_\n",
    "# Making a list of the importances and the feature names. \n",
    "whiteFeatureImportanceList = sorted(list(zip(whiteTrainingData.columns, whiteFeatureImportance)), key=lambda x:x[1], reverse=True)\n",
    "print(\"The 5 most importance features in the Random Forest Classifier Model made to predict the quality of Red Wine are: \")\n",
    "# Getting the 5 most importance features\n",
    "for i in range(5):\n",
    "    print(whiteFeatureImportanceList[i])\n",
    "# Printing out the precision score.\n",
    "print(\"The Random Forest Classifier model made to predict the White Wine Quality has an precision of \" + str(whiteScoreRF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for the SVM used to model the Red Wine training data is 0.5998125585754451\n",
      "The score for the SVM used to model the Red Wine test data is 0.5695488721804511\n",
      "[('fixed acidity', 0.5480521123718827), ('volatile acidity', 0.4818175390776087), ('citric acid', 0.6688554517617892), ('residual sugar', 0.2762336492578549), ('chlorides', 0.2511072948233213), ('free sulfur dioxide', 0.07696827692871955), ('total sulfur dioxide', -1.103416131262917), ('density', 0.7129117630460664), ('pH', 0.5346304045970975), ('sulphates', -0.29440240327862965), ('alcohol', -0.3370718213157221)]\n",
      "('density', 0.7129117630460664)\n",
      "('citric acid', 0.6688554517617892)\n",
      "('fixed acidity', 0.5480521123718827)\n",
      "('pH', 0.5346304045970975)\n",
      "('volatile acidity', 0.4818175390776087)\n",
      "[7 7 5 6 5 5 5 5 6 7 6 6 5 7 5 5 6 5 5 6 6 6 6 6 6 6 7 5 5 5 5 7 5 7 6 6 6\n",
      " 7 6 7 7 5 6 6 6 6 5 7 6 6 6 7 7 7 6 6 6 6 6 7 6 5 6 6 5 7 6 7 6 6 6 5 5 5\n",
      " 6 6 6 5 6 6 6 6 6 7 6 5 6 6 5 6 6 6 6 6 6 7 5 5 5 6 7 6 6 6 6 7 5 5 6 5 7\n",
      " 5 6 6 6 6 5 5 6 6 6 5 5 7 5 7 5 5 5 5 5 6 5 5 6 6 5 6 6 6 5 6 7 5 5 5 6 6\n",
      " 6 5 6 6 6 6 6 5 7 6 5 5 5 6 5 6 5 5 6 6 5 5 6 5 6 5 5 6 5 5 5 5 5 6 6 6 5\n",
      " 5 5 6 5 5 5 6 6 5 5 5 5 6 5 5 7 5 7 7 6 6 5 6 5 7 5 5 6 5 5 6 5 6 6 7 7 5\n",
      " 5 6 6 7 5 6 5 5 6 6 5 6 6 6 6 5 5 5 5 5 5 5 7 5 5 5 5 6 6 5 5 5 6 6 6 5 5\n",
      " 5 5 5 5 5 5 5 5 5 6 5 5 5 6 6 6 5 6 6 5 6 5 5 6 5 6 5 5 5 5 5 6 5 6 6 5 6\n",
      " 5 6 5 5 5 5 5 5 7 5 5 5 5 5 6 5 6 6 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 6\n",
      " 5 5 6 6 5 6 6 6 7 6 5 5 6 6 6 5 6 6 5 5 5 5 6 6 5 5 6 6 6 6 5 5 6 5 3 3 5\n",
      " 5 5 5 6 5 5 6 5 5 5 5 5 6 6 6 6 5 6 5 5 5 6 7 5 5 5 5 5 5 5 5 5 5 5 7 6 5\n",
      " 3 7 3 7 5 6 5 6 5 6 5 5 5 6 6 6 7 6 6 5 6 6 5 6 5 6 5 5 5 6 6 5 5 6 6 6 5\n",
      " 5 5 5 5 5 6 6 5 5 6 5 6 5 5 5 5 6 5 5 6 5 5 5 6 5 5 5 6 5 6 6 5 6 6 5 5 6\n",
      " 6 6 5 5 6 5 5 6 5 5 5 5 5 5 5 5 5 6 6 5 5 6 7 6 5 6 5 6 6 6 6 6 6 6 6 5 6\n",
      " 6 6 5 6 5 6 5 6 5 5 6 6 5 5]\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "# Making a SVM object.\n",
    "redSVM = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the model using the redTrainingDataScaled data, and the redQualityTrainingData as the target variable. \n",
    "redSVM.fit(redTrainingDataScaled, redQualityTrainingData)\n",
    "# Getting the redTrainingDataScaled score.\n",
    "redSVMScoreTraining = redSVM.score(redTrainingDataScaled, redQualityTrainingData)\n",
    "# Printing out the score for the SVM mdel made above. \n",
    "print(\"The score for the SVM used to model the Red Wine training data is \" + str(redSVMScoreTraining))\n",
    "# Getting the redTestDataScaled score.\n",
    "redSVMScoreTest = redSVM.score(redTestDataScaled, redQualityTestData)\n",
    "# Printing out the score for the SVM mdel made above. \n",
    "print(\"The score for the SVM used to model the Red Wine test data is \" + str(redSVMScoreTest))\n",
    "# Calculating the coefficient for the SVM model used for the training data. \n",
    "redSVMTrainingCoeff = redSVM.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importanceRedSVM = redSVMTrainingCoeff[0]\n",
    "# Making a list of the feature names, the importance coeffeicient.\n",
    "importanceRedList = list(zip(redTrainingData.columns, importanceRedSVM))\n",
    "# Sorting the list of importance of the features. \n",
    "importanceRedList.sort(key=lambda x: x[1], reverse=True)\n",
    "# Printing out the 5 most important features.\n",
    "for i in range(5):\n",
    "    print(importanceRedList[i])\n",
    "# Getting the probablity of the prediction, using the redTrainingDataScaled.\n",
    "redTestProbability = redSVM.predict_proba(redTestDataScaled)\n",
    "# Getting the prediction values for the redTestDataScaled. \n",
    "redPredictionValues = redSVM.predict(redTestDataScaled)\n",
    "\n",
    "# Making a SVM object.\n",
    "whiteSVM = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the model using the redTrainingDataScaled data, and the redQualityTrainingData as the target variable. \n",
    "whiteSVM.fit(whiteTrainingDataScaled, whiteQualityTrainingData)\n",
    "# Getting the redTrainingDataScaled score.\n",
    "whiteSVMScoreTraining = whiteSVM.score(whiteTrainingDataScaled, whiteQualityTrainingData)\n",
    "# Printing out the score for the SVM mdel made above. \n",
    "print(\"The score for the SVM used to model the White Wine training data is \" + str(whiteSVMScoreTraining))\n",
    "# Getting the redTestDataScaled score.\n",
    "whiteSVMScoreTest = whiteSVM.score(whiteTestDataScaled, whiteQualityTestData)\n",
    "# Printing out the score for the SVM mdel made above. \n",
    "print(\"The score for the SVM used to model the White Wine test data is \" + str(redSVMScoreTest))\n",
    "# Calculating the coefficient for the SVM model used for the training data. \n",
    "whiteSVMTrainingCoeff = whiteSVM.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importanceWhiteSVM = whiteSVMTrainingCoeff[0]\n",
    "# Making a list of the feature names, the importance coeffeicient.\n",
    "importanceWhiteList = list(zip(whiteTrainingData.columns, importanceWhiteSVM))\n",
    "# Sorting the list of importance of the features. \n",
    "importanceWhiteList.sort(key=lambda x: x[1], reverse=True)\n",
    "# Printing out the 5 most important features.\n",
    "for i in range(5):\n",
    "    print(importanceWhiteList[i])\n",
    "# Getting the probablity of the prediction, using the redTrainingDataScaled.\n",
    "whiteTestProbability = whiteSVM.predict_proba(whiteTestDataScaled)\n",
    "# Getting the prediction values for the redTestDataScaled. \n",
    "whitePredictionValues = whiteSVM.predict(whiteTestDataScaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
